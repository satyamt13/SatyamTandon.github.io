# NLP and Recommender Systems with Amazon Movies & TV Reviews
## Short Summary 
* Efficiently mined over 1 million observations of Amazon reviews on a 4-core local machine using big data principles like parallel processing and data streaming with Gensim and Numpy.
* Adapted a special C-LSTM Neural Network based on the Zhou et al. 2015 research paper using Keras that beat a simple majority baseline by 10% and a simple Naive Bayes baseline by 6% for multi-class sentiment classification with T.V. & Movie ratings.
* Used SVD with Scikit-Learn to build a collaborative filtering recommender system for Movies and T.V. shows from the data.
### [README.md](https://github.com/satyamt13/Project_Amazon_reviews_NLP_recommender_system)  &nbsp; &nbsp; [Jupyter Notebook](https://github.com/satyamt13/Project_Amazon_reviews_NLP_recommender_system/blob/master/CNN_LSTM_approach.ipynb)

<br>

# Data Science Industry Challenge: EDA, time-series data, experiments and metrics design, machine learning
## Short Summary 
* Removed noise and visualized trends in customer demand using time-series smoothening and aggregation on login data with Seaborn and Pandas to identify peak and slow periods for a ride-hailing service.
* Theorized an A/B Testing experiment and metric design to ascertain the impact of toll reimbursement for drivers on cross-state trip willingness.
* Predicted customer churn using feature engineering with tuned ensemble methods such as Random Forest and SG Boosting which achieved a high stratified accuracy of 85% on the class of interest (churn) while maintaining a reasonable overall accuracy of 78% on test data.
* Wrote scripts using Scikit-Learn to visualize classification report and confusion matrix for each model used. 
### [Jupyter Notebook](https://github.com/satyamt13/data_science_challenge1)

<br>

# Analysis of Pronto, a bicycle share system in Seattle, WA
## Short Summary
* Identified two machine-learning uses cases of predicting number of trips per day based on weather attributes and destination dock of a bicycle once it had been checked out by a member without being given any concrete problem structure.
* Heavily wrangled data and started with simpler models such as ridge and lasso regression and K-nearest neighbors with Pandas and Scikit-Learn before moving on to more complex models such as XGBoost regressor and classifier respectively on AWS EC2 instances to achieve an increase in performance
### [Github Repo](https://github.com/satyamt13/Capstone_1) &nbsp; &nbsp; [Jupyter Notebook](https://github.com/satyamt13/Capstone_1/blob/master/Capstone1_ML_models.ipynb)

<br>

# Data Science Industry Challenge, Relaxo inc: Feature Engineering, Machine Learning
## Short Summary 
* Identified and constructed the target variable from two separate datasets manipulating categorical and date time object data. Trained , validated and tested a random forest classifier on the data to be able to predict customer churn.
* Intuitively engineered three additional features from given data which proved paramount in achieving an extremely high overall accuracy(98.07%) , high precision(98.3%) and high recall(96.8%) on the unseen/hold out set.
### [Jupyter Notebook](https://github.com/satyamt13/data_science_challenge2/blob/master/relax_data_science_challenge_notebook.ipynb)

<br>

# Predicting Employee Turnover with ensemble methods
## Short Summary
* Visualized breakdown , pre-processed and cleaned data for robust ensemble methods such as voting , bagging and boosting. Fine tuned and validated each model based on metrics I identified as being more important than just model accuracy w.r.t the problem of employee turnover.
* Wrote scripts to visualize the performance and classi􀂁cation report of each validated model on the unseen/holdout data.
* Wrote up a full report explaining my findings, processes and provided recommendations tailored to the need of organizations of various sizes.
### [Github Repo](https://github.com/satyamt13/Capstone2) &nbsp; &nbsp; [Jupyter Notebook](https://github.com/satyamt13/Capstone2/blob/master/Capstone2.ipynb)

